
import { GoogleGenAI, Modality, HarmCategory, HarmBlockThreshold, Type } from "@google/genai";
import { API_KEY } from "../config";
import { ImageData } from "../types";

// Per coding guidelines, the AI client is initialized directly.
// It is assumed the API_KEY is pre-configured and accessible in the environment.
// The GenAI library will handle an invalid or missing key.
const ai = new GoogleGenAI({ apiKey: API_KEY });


// Define strict safety settings to prevent unsafe content generation.
const safetySettings = [
  {
    category: HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
  },
];

// System instruction to prevent processing images of minors.
const systemInstruction = "You are a responsible AI image editing assistant. Your most critical safety rule is to never process, edit, or generate images that depict children or individuals who appear to be under 18 years of age. If an uploaded image seems to contain a minor, you must strictly refuse the request. Do not proceed with the edit. Instead, reply with only the following text: 'Error: Image appears to contain a child and cannot be processed.'";

// Refactored to remove the conditional check for the `ai` client.
// This aligns with the guideline to assume the API key is always available.
export const editImageWithGemini = async (
  originalImage: ImageData,
  prompt: string,
  referenceImage: ImageData | null = null
): Promise<string> => {
  const parts: any[] = [
    {
      inlineData: {
        data: originalImage.base64,
        mimeType: originalImage.mimeType,
      },
    },
  ];

  if (referenceImage) {
    parts.push({
      inlineData: {
        data: referenceImage.base64,
        mimeType: referenceImage.mimeType,
      },
    });
  }

  parts.push({ text: prompt });

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image-preview',
      contents: { parts: parts },
      config: {
        responseModalities: [Modality.IMAGE, Modality.TEXT],
        safetySettings,
        systemInstruction,
      },
    });

    // Per system instruction, check for text-based error response
    if (response.text?.trim().startsWith("Error:")) {
        throw new Error(response.text.trim());
    }

    // According to guidelines, loop through parts to find image data
    for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
            return part.inlineData.data;
        }
    }

    throw new Error("No image was generated by the AI. The model may have refused the request due to safety policies.");
  } catch (error) {
    console.error("Gemini API error:", error);
    let friendlyMessage = "An error occurred while communicating with the AI. Please try again.";
    if (error instanceof Error) {
        if(error.message.includes('SAFETY')) {
            friendlyMessage = "The request was blocked due to safety settings. Please ensure your prompt and image are appropriate.";
        } else {
            friendlyMessage = error.message;
        }
    }
    throw new Error(friendlyMessage);
  }
};

// Refactored to remove the conditional check for the `ai` client.
// This aligns with the guideline to assume the API key is always available.
export const detectGenderWithGemini = async (image: ImageData): Promise<'male' | 'female'> => {
  const prompt = "Analyze the provided image and determine the most likely gender of the person. Respond in JSON format with a single key 'gender' which can be either 'male' or 'female'.";
  
  const imagePart = {
    inlineData: {
      mimeType: image.mimeType,
      data: image.base64,
    },
  };

  const textPart = {
    text: prompt
  };

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: { parts: [imagePart, textPart] },
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            gender: {
              type: Type.STRING,
              description: "The detected gender of the person, either 'male' or 'female'.",
            },
          },
        },
        safetySettings,
        systemInstruction
      },
    });

    const jsonText = response.text?.trim();
    if (!jsonText) {
        throw new Error("AI returned an empty response for gender detection.");
    }

    if (jsonText.startsWith("Error:")) {
        throw new Error(jsonText);
    }

    const result = JSON.parse(jsonText);

    if (result.gender && (result.gender.toLowerCase() === 'male' || result.gender.toLowerCase() === 'female')) {
      return result.gender.toLowerCase();
    } else {
      throw new Error("Could not determine gender from the AI response.");
    }
  } catch (error) {
    console.error("Gemini gender detection error:", error);
    let friendlyMessage = "An error occurred while detecting gender. Please select a gender manually.";
    if (error instanceof Error) {
        if(error.message.includes('SAFETY')) {
            friendlyMessage = "The request was blocked due to safety settings. This may happen if the image contains a minor.";
        } else if (error.message.includes('JSON')) {
            friendlyMessage = "The AI returned an invalid format for gender detection. Please select a gender manually.";
        } else {
            friendlyMessage = error.message;
        }
    }
    throw new Error(friendlyMessage);
  }
};
